<!DOCTYPE html>
<html>
  <head>
    <title>ImageBitmap Extensions</title>
    <meta charset='utf-8'>
    <script src='https://www.w3.org/Tools/respec/respec-w3c-common'
            async class='remove'></script>
    <script class='remove'>
      var respecConfig = {
          // specification status (e.g. WD, LCWD, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "ED",

          // the specification's short name, as in http://www.w3.org/TR/short-name/
          // shortName:            "imagebitmap-extension",

          // if your specification has a subtitle that goes below the main
          // formal title, define it here
          // subtitle   :  "an excellent document",

          // if you wish the publication date to be other than the last modification, set this
          // publishDate:  "2009-08-06",

          // if the specification's copyright date is a range of years, specify
          // the start date here:
          // copyrightStart: "2005"

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "http://kakukogou.github.io/spec-imagebitmap-extension",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2009-08-05",

          // editors, add as many as you like
          // only "name" is required
          editors:  [
              {
                name:       "Tzuhao Kuo",
                company:    "Mozilla",
                companyURL: "http://www.mozilla.com/"
              },
              {
                name:       "Chiahung Tai",
                company:    "Mozilla",
                companyURL: "http://www.mozilla.com/"
              },
              {
                name:       "Robert O'Callahan",
                company:    "Mozilla",
                companyURL: "http://www.mozilla.com/"
              }
          ],

          // name of the WG
          wg:           "In Charge Of This Document Working Group",

          // URI of the public WG page
          wgURI:        "http://example.org/really-cool-wg",

          // name (without the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "spec-writers-anonymous",

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "",
          // !!!! IMPORTANT !!!! MAKE THE ABOVE BLINK IN YOUR HEAD
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This specification extends the <a><code>ImageBitmap interface</code></a>
        to allow JavaScript developers to read the underlying data out and set
        an external data into an <a><code>ImageBitmap</code></a> in a set of
        supported color formats.
      </p>
      <p>

      </p>
    </section>

    <section id='sotd'>
      <p>
        <strong>This document is not complete and is subject to change. Early
        experimentations are encouraged to allow the Media Capture Task Force
        to evolve the specification based on technical discussions within the
        Task Force, implementation experience gained from early
        implementations, and feedback from other groups and
        individuals.</strong>
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
        The <a><code>ImageBitmap interface</code></a> is originally designed as
        a pure opaque handler to an image data buffer inside a browser so that
        how it stores the buffer is uknown to users and optimized to platforms.
      </p>
      <p>
        Currently, the <em>Media Capture Stream with Video Worker</em>
        specification [<a>mediacapture-worker</a>] proposes a video processing
        framework on the web platform. It provides web applications a way to
        hook a script (ran in a Web Worker) to a video track (of a MediaStream)
        so that each frame will be processed accordingly. If the worker is
        successfully hooked to a track, the framework will post a
        <code>VideoProcessEvent</code> to the worker per frame.
        A <code>VideoProcessEvent</code> has an <code>inputImageBitmap</code>
        property and an <code>outputImageBitmap</code> property so that
        JavaScript developers could read the raw image data of the current video
        frame out from the <code>inputImageBitmap</code>, then after some
        processing, write the processed image data back into the
        <code>outputImageBitmap</code>. This specification is meant to extend
        the <a>ImageBitmap interface</a> with new APIs to read data
        from and write data back into an <code>ImageBitmap</code>.
      </p>
      <p>
        The <em>Media Capture Stream with Video Worker</em> specification
        [<a>mediacapture-worker</a>] chooses <a><code>ImageBitmap</code></a>
        (instead of <code>ImageData</code>) as the container of video frames
        because the decoded video frame data might exist in either CPU or GPU
        memory which perfectly matches the nature of
        <a><code>ImageBitmap</code></a> as an opaque handler.
      </p>
      <p>
        Considering how would developers process video frames, there are two possible
        ways, via JavaScript(/asm.js) or WebGL.
        <ol>
          <li>
            If developers use WebGL, then treating an ImageBitmap as an opaque
            container, passing it into the WebGL context and the browser will
            handle how to uploade the ras image data into the GPU memory.
            Possiblely, the dada is already in the GPU memory so that no further
            operation is needed through.
          </li>
          <li>
            If developers use JavaScript(/asm.js) to process the frames, then
            new APIs to access the raw data inside an ImageBitmp are needed
            since the current <a><code>ImageBitmap interface</code></a> provides
            no way for developers to do so.
          </li>
        </ol>
      </p>
    </section>

    <section>
      <h2>
        Dependencies
      </h2>
      <p>
        The <code><a href=
        "http://www.w3.org/TR/html51/webappapis.html#images">
        <dfn>ImageBitmap interface</dfn></a></code> this specification extends
        are defined in [[!HTML51]].
      </p>
      <p>
        The <em>Media Capture Stream with Video Worker</em> specificaton proposes a video
        processing framework on the web platform.
        [<a href="http://chiahungtai.github.io/mediacapture-worker/">
        <dfn>mediacapture-worker</dfn></a>]
      </p>
    </section>

    <section>
      <h2>Color format</h2>
      <p>
        Image/Video data might exists in a variety of color formats. Developers need
        to know how the data is formated so that they are able to process it.
        Information that we need to know about a color format includes color space,
        channel permutation and the pixel layout. A color space is the space used to
        express colors; the space is constructed by coordinates which is called color
        channels. An image or video frame is composed by pixels and each pixel's
        color is represented by values from all channels of a given color space. The
        pixel values might be arranged in a planar way or interleaving way:
        <ol>
          <li>
            Planar layout: each channel has its pixel values stored consecutively in
            separated buffers (/planes) and channel buffers are stored consecutively
            in memory.
            (Ex: RRRRRR......GGGGGG......BBBBBB......)
          </li>
          <li>
            Interleaving layout: each pixel has its pixel values from all channels
            stored together and interleaves all channels.
            (Ex: RGBRGBRGBRGBRGB......)
          </li>
        </ol>
        <div class="note">
          <p>
            Color formats belong to the same color space might have different
            pixel layouts.
          </p>
        </div>
      </p>
    </section>

    <section>
      <h2>Components</h2>

      <section>
        <h2>ColorFormat</h2>
        <p>
          An enumeration <a>ColorFormat</a> defines a list of color formats
          which are exposed to users. The extend APIs of <a>ImageBitmap</a> use
          this enumeration to negotiate the format while accessing the
          underlying data of <a>ImageBitmap</a> and writing back.
        </p>
        <div class="note">
          <p>
            We need to elaborate this list for standardization.
          </p>
        </div>
        <dl id="enum-basic" class="idl" title="enum ColorFormat">
          <dt>RGBA32</dt>
          <dd>
            <p>Channel order: R, G, B, A</p>
            <p>Channel size: full rgba-chennels</p>
            <p>Pixel layout: interleaving rgba-channels</p>
          </dd>
          <dt>BGRA32</dt>
          <dd>
            <p>Channel order: B, G, R, A</p>
            <p>Channel size: full bgra-channels</p>
            <p>Pixel layout: interleaving bgra-channels</p>
          </dd>
          <dt>RGB24</dt>
          <dd>
            <p>Channel order: R, G, B</p>
            <p>Channel size: full rgb-channels</p>
            <p>Pixel layout: interleaving rgb-channels</p>
          </dd>
          <dt>BGR24</dt>
          <dd>
            <p>Channel order: B, G, R</p>
            <p>Channel size: full bgr-channels</p>
            <p>Pixel layout: interleaving bgr-channels</p>
          </dd>
          <dt>GRAY8</dt>
          <dd>
            <p>Channel order: GRAY</p>
            <p>Channel size: full gray-channel</p>
            <p>Pixel layout: planar gray-channel</p>
          </dd>
          <dt>YUV444P</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full yuv-channels</p>
            <p>Pixel layout: planar yuv-channels</p>
          </dd>
          <dt>YUV422P</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full y-channel, half uv-channels</p>
            <p>Pixel layout: planar yuv-channels</p>
          </dd>
          <dt>YUV420P</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full y-channel, quarter uv-channels</p>
            <p>Pixel layout: planar yuv-channels</p>
          </dd>
          <dt>YUV420SP_NV12</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full y-channel, quarter uv-channels</p>
            <p>Pixel layout: planar y-channel, interleaving uv-channels</p>
          </dd>
          <dt>YUV420SP_NV21</dt>
          <dd>
            <p>Channel order: Y, V, U</p>
            <p>Channel size: full y-channel, quarter uv-channels</p>
            <p>Pixel layout: planar y-channel, interleaving vu-channels</p>
          </dd>
          <dt>HSV</dt>
          <dd>
            <p>Channel order: H, S, V</p>
            <p>Channel size: full hsv-channels</p>
            <p>Pixel layout: interleaving hsv-channels</p>
          </dd>
          <dt>Lab</dt>
          <dd>
            <p>Channel order: l, a, b</p>
            <p>Channel size: full lab-channels</p>
            <p>Pixel layout: interleaving lab-channels</p>
          </dd>
          <dt>DEPTH</dt>
          <dd>
            <p>Channel order: DEPTH</p>
            <p>Channel size: full depth-channel</p>
            <p>Pixel layout: planar depth-channel</p>
          </dd>
        </dl>
      </section>

      <section>
        <h2>PixelLayout</h2>
        <p>
          Two interfaces, <a>ColorFormatPixelLayout</a> and
          <a>ChannelPixelLayout</a>, help together to generalize the variety of
          pixel layouts among color formats.
        </p>
        <p>
          The <a>ColorFormatPixelLayout</a> represents the pixel layout of a
          certain color space and since a color format is composed by at least
          one channel so <a>ColorFormatPixelLayout</a> contains at least one
          <a>ChannelPixelLayout</a>.
        </p>
        <p>
          Although an Image/Video frame is a two-dimensional structure, its data
          is usually stored in an one-dimensional array and the
          <a>ChannelPixelLayout</a> use the following properties to describe the
          layout of pixel values in the one dimentional array buffer.
          <ol>
            <li>
              <em>offset</em>: where is each channel's data starts from.
              (Relative to the beginning of the video data one-dimension array.)
            </li>
            <li>
              <em>width</em> and <em>height</em>:
              how much samples are in each channel.
            </li>
            <li>
              <em>stride</em>: the padding of each row.
              (Memory alignment purpose.)
            </li>
            <li>
              <em>skip</em>: this is used to describe interleaving layout.
              (For planar layout, this property will be zero.)
            </li>
          </ol>
        </p>

        <pre class='example highlight'>
          Example1: RGBA image, width = 620, height = 480, stride = 2560

          chanel_r: offset = 0, width = 620, height = 480, stride = 2560, skip = 3
          chanel_g: offset = 1, width = 620, height = 480, stride = 2560, skip = 3
          chanel_b: offset = 2, width = 620, height = 480, stride = 2560, skip = 3
          chanel_a: offset = 3, width = 620, height = 480, stride = 2560, skip = 3

                  <---------------------------- stride ---------------------------->
                  <---------------------- width x 4 ---------------------->
          [index] 01234   8   12  16  20  24  28                           2479    2559
                  |||||---|---|---|---|---|---|----------------------------|-------|
          [data]  RGBARGBARGBARGBARGBAR___R___R...                         A%%%%%%%%
          [data]  RGBARGBARGBARGBARGBAR___R___R...                         A%%%%%%%%
          [data]  RGBARGBARGBARGBARGBAR___R___R...                         A%%%%%%%%
                       ^^^
                       r-skip
        </pre>

        <pre class='example highlight'>
          Example2: YUV420P image, width = 620, height = 480, stride = 640

          chanel_y: offset = 0, width = 620, height = 480, stride = 640, skip = 0
          chanel_u: offset = 307200, width = 310, height = 240, stride = 320, skip = 0
          chanel_v: offset = 384000, width = 310, height = 240, stride = 320, skip = 0

                  <--------------------------- y-stride --------------------------->
                  <----------------------- y-width ----------------------->
          [index] 012345                                                  619      639
                  ||||||--------------------------------------------------|--------|
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                        Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                        Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                        Y%%%%%%%%%
          [data]  ......
                  <-------- u-stride ---------->
                  <----- u-width ----->
          [index] 307200              307509   307519
                  |-------------------|--------|
          [data]  UUUUUUUUUU...       U%%%%%%%%%
          [data]  UUUUUUUUUU...       U%%%%%%%%%
          [data]  UUUUUUUUUU...       U%%%%%%%%%
          [data]  ......
                  <-------- v-stride ---------->
                  <- --- v-width ----->
          [index] 384000              384309   384319
                  |-------------------|--------|
          [data]  VVVVVVVVVV...       V%%%%%%%%%
          [data]  VVVVVVVVVV...       V%%%%%%%%%
          [data]  VVVVVVVVVV...       V%%%%%%%%%
          [data]  ......
        </pre>

        <pre class='example highlight'>
          Example3: YUV420SP_NV12 image, width = 620, height = 480, stride = 640

          chanel_y: offset = 0, width = 620, height = 480, stride = 640, skip = 0
          chanel_u: offset = 307200, width = 310, height = 240, stride = 640, skip = 1
          chanel_v: offset = 307201, width = 310, height = 240, stride = 640, skip = 1

                  <--------------------------- y-stride -------------------------->
                  <----------------------- y-width ---------------------->
          [index] 012345                                                 619      639
                  ||||||-------------------------------------------------|--------|
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                       Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                       Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                       Y%%%%%%%%%
          [data]  ......
                  <--------------------- u-stride / v-stride -------------------->
                  <------------------ u-width + v-width ----------------->
          [index] 307200(u-offset)                                       307819  307839
                  |------------------------------------------------------|-------|
          [index] |307201(v-offset)                                      |307820 |
                  ||-----------------------------------------------------||------|
          [data]  UVUVUVUVUVUVUVUVUVUVUVUVUVUVUV...                      UV%%%%%%%
          [data]  UVUVUVUVUVUVUVUVUVUVUVUVUVUVUV...                      UV%%%%%%%
          [data]  UVUVUVUVUVUVUVUVUVUVUVUVUVUVUV...                      UV%%%%%%%
                   ^            ^
                  u-skip        v-skip
        </pre>

        <section>
          <h2>ColorFormatPixelLayout</h2>
          <dl class="idl" title="[Exposed=(Window,Worker)] interface ChannelPixelLayout">
            <dt>
              [Constant]
              readonly attribute unsigned long offset
            </dt>
            <dd>
              <p>
                The beginning position of this channel's data (relative to the given
                ArrayBuffer parameter of the mapDataInto() method.)
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long width
            </dt>
            <dd>
              <p>
                The width of this channel.
                Channels in a color format may have different width.
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long height
            </dt>
            <dd>
              <p>
                The height of this channel.
                Channels in a color format may have different height.
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long stride
            </dt>
            <dd>
              <p>
                The stride of this channel.
                This is used to describe the padding of this channel.
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long skip
            </dt>
            <dd>
              <p>
                This is used to describe how much bytes between two adjacent pixel values
                in this channel.
              </p>
              <p>
                Possible values:
                <ul>
                  <li>
                    zero: for planar format.
                  </li>
                  <li>
                    a positive integer: for interleaving format.
                  </li>
                </ul>
              </p>
            </dd>
          </dl>
        </section>

        <section>
          <h2>ChannelPixelLayout</h2>
          <dl class="idl" title="[Exposed=(Window,Worker)] interface ColorFormatPixelLayout">
            <dt>
              [Constant, Cached]
              readonly attribute sequence&lt;ChannelPixelLayout&gt; channels
            </dt>
            <dd>
              <p>
                Channel information of this color format.
                Each color format has at least one channel.
              <p>
            </dd>
          </dl>
        </section>
      </section>

      <section>
        <h2>ImageBitmap extensions</h2>
        <div class="note">
          <p>
            We need to redesign the "setDataFrom()" method.
          </p>
        </div>
        <dl class="idl" title="[Exposed=(Window,Worker)] partial interface ImageBitmap">
          <dt>
            ColorFormat findOptimalFormat()
          </dt>
          <dd>
            <p>
              Find the best color format for receiving data.
            </p>
            <p>
              @return one of the <code>possibleFormats</code> or the empty
              string if no any format in the list is supported. If the
              <code>possibleFormats</code> is not given, then returns the most
              suitable color format for this ImageBitmap from all supported
              color formats.
            </p>
            <dl class="parameters">
              <dt>optional sequence&lt;ColorFormat&gt; possibleFormats</dt>
              <dd>
                <p>A list of color formats that users can handler.</p>
              </dd>
            </dl>
          </dd>

          <dt>
            [Throws]
            long mappedDataLength()
          </dt>
          <dd>
            <p>
              Calculate the length of mapped data wile the image is represented
              in the given <code>format</code>.
            </p>
            <p>
              Throws if <code>format</code> is not supported.
            </p>
            <p>
              @return the length (in bytes) of image data the represented in the
              given <code>format</code>.
            </p>
            <dl class="parameters">
              <dt>ColorFormat format</dt>
              <dd>
                <p>The format that users want.</p>
              </dd>
            </dl>
          </dd>

          <dt>
            [Throws]
            Promise&lt;ColorFormatPixelLayout&gt; mapDataInto()
            <!-- ColorFormatPixelLayout mapDataInto() -->
          </dt>
          <dd>
            <p>
              Makes a copy of the underlying image data in the given format
              <code>format</code> into the given <code>buffer</code> at offset
              <code>offset</code>, filling at most <code>length</code> bytes and
              returns a <a>ColorFormatPixelLayout</a> object which describes the
              pixel layout.
            </p>
            <p>
              Throws if <code>format</code> is not supported.
            </p>
            <p>
              Each time this method is invoked returns a new
              <a>ColorFormatPixelLayout</a> object.
            </p>
            <p>
              @return a <a>ColorFormatPixelLayout</a> object which describes the
              pixel layout.
            </p>
            <dl class="parameters">
              <dt>ColorFormat format</dt>
              <dd>
                <p>The format that users want.</p>
              </dd>
              <dt>ArrayBuffer buffer</dt>
              <dd>
                <p>A container for receiving the mapped image data.</p>
              </dd>
              <dt>long offset</dt>
              <dd>
                <p>
                  The beginning position of the <code>buffer</code> to place
                  the mapped data.
                </p>
              </dd>
              <dt>long length</dt>
              <dd>
                <p>
                  The length of space in the <code>buffer</code> that could be
                  filled.
                </p>
              </dd>
            </dl>
          </dd>

          <dt>
            [Throws]
            boolean setDataFrom()
          </dt>
          <dd>
            <p>
              We need to redesign this one.......
            </p>
            <dl class="parameters">
              <dt>ColorFormat format</dt>
              <dd>
                <p>The format that users want.</p>
              </dd>
              <dt>ArrayBuffer buffer</dt>
              <dd>
                <p>A container for receiving the mapped image data.</p>
              </dd>
              <dt>long offset</dt>
              <dd>
                <p>
                  The beginning position of the <code>buffer</code> to place the
                  mapped data.
                </p>
              </dd>
              <dt>long length</dt>
              <dd>
                <p>
                  The length of space in the <code>buffer</code> that could be
                  filled.
                </p>
              </dd>
              <dt>long width</dt>
              <dd>
                <p>The width of the input image.</p>
              </dd>
              <dt>long height</dt>
              <dd>
                <p>The height of the input image.</p>
              </dd>
              <dt>long stride</dt>
              <dd>
                <p>The stride of the input image. (?)</p>
              </dd>

            </dl>
          </dd>
        </dl>
      </section>

    </section>

    <section class='appendix'>
      <h2>Acknowledgements</h2>
      <p>
        Thanks to Jeff Muizelaar for providing insightful oppinions in the APIs
        design and the experimantal implement.
      </p>
    </section>
  </body>
</html>
